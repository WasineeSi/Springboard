{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07086a5f",
   "metadata": {},
   "source": [
    "# Preprocessing Training and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e8acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800e98c",
   "metadata": {},
   "source": [
    "## Preprocessing and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbbf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fraudTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b14a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleted first column since it was the same as the index\n",
    "df = df.iloc[: , 1:]\n",
    "# We are going to rename some columns for ease\n",
    "df = df.rename(columns={'trans_date_trans_time':'date_time'})\n",
    "# Drop any duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9bd3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1296675, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb36daf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12967, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's downsize the data for ease of speed\n",
    "df = df.sample(frac=0.01)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dbf6dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>844251</th>\n",
       "      <td>2019-12-14 14:24:34</td>\n",
       "      <td>3577578023716568</td>\n",
       "      <td>fraud_Connelly-Carter</td>\n",
       "      <td>home</td>\n",
       "      <td>61.30</td>\n",
       "      <td>Debbie</td>\n",
       "      <td>Hughes</td>\n",
       "      <td>F</td>\n",
       "      <td>0182 Owens Burgs Suite 480</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0935</td>\n",
       "      <td>-81.0425</td>\n",
       "      <td>2644</td>\n",
       "      <td>Engineer, biomedical</td>\n",
       "      <td>1983-08-25</td>\n",
       "      <td>26adc9780adf68d32f2806e7e24d9607</td>\n",
       "      <td>1355495074</td>\n",
       "      <td>41.182834</td>\n",
       "      <td>-80.598998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073400</th>\n",
       "      <td>2020-03-22 06:33:04</td>\n",
       "      <td>4822367783500458</td>\n",
       "      <td>fraud_Smitham-Boehm</td>\n",
       "      <td>grocery_net</td>\n",
       "      <td>49.51</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Farrell</td>\n",
       "      <td>M</td>\n",
       "      <td>97070 Anderson Land</td>\n",
       "      <td>Haines City</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0758</td>\n",
       "      <td>-81.5929</td>\n",
       "      <td>33804</td>\n",
       "      <td>Exercise physiologist</td>\n",
       "      <td>1991-01-01</td>\n",
       "      <td>02e371db409e3999b37e297a3e7b1f49</td>\n",
       "      <td>1363933984</td>\n",
       "      <td>27.454865</td>\n",
       "      <td>-81.846996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035705</th>\n",
       "      <td>2020-03-05 07:38:39</td>\n",
       "      <td>4512828414983801773</td>\n",
       "      <td>fraud_Kutch-Hegmann</td>\n",
       "      <td>grocery_net</td>\n",
       "      <td>50.88</td>\n",
       "      <td>Monica</td>\n",
       "      <td>Cohen</td>\n",
       "      <td>F</td>\n",
       "      <td>864 Reynolds Plains</td>\n",
       "      <td>Uledi</td>\n",
       "      <td>...</td>\n",
       "      <td>39.8936</td>\n",
       "      <td>-79.7856</td>\n",
       "      <td>328</td>\n",
       "      <td>Tree surgeon</td>\n",
       "      <td>1983-07-25</td>\n",
       "      <td>a2db8ea2d74b5970267465073343cc1f</td>\n",
       "      <td>1362469119</td>\n",
       "      <td>39.880428</td>\n",
       "      <td>-80.729349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142571</th>\n",
       "      <td>2020-04-20 23:57:09</td>\n",
       "      <td>2222157926772399</td>\n",
       "      <td>fraud_Rau-Grant</td>\n",
       "      <td>kids_pets</td>\n",
       "      <td>130.63</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Garrett</td>\n",
       "      <td>F</td>\n",
       "      <td>6014 Thomas Throughway</td>\n",
       "      <td>Trenton</td>\n",
       "      <td>...</td>\n",
       "      <td>33.4235</td>\n",
       "      <td>-96.3398</td>\n",
       "      <td>2211</td>\n",
       "      <td>Investment banker, operational</td>\n",
       "      <td>1987-02-26</td>\n",
       "      <td>d3a3fbb5187f2650287c335489edfb5e</td>\n",
       "      <td>1366502229</td>\n",
       "      <td>34.250078</td>\n",
       "      <td>-95.344471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269503</th>\n",
       "      <td>2019-05-13 10:44:33</td>\n",
       "      <td>30030380240193</td>\n",
       "      <td>fraud_Terry-Huel</td>\n",
       "      <td>shopping_net</td>\n",
       "      <td>95.43</td>\n",
       "      <td>William</td>\n",
       "      <td>Jenkins</td>\n",
       "      <td>M</td>\n",
       "      <td>50614 Kevin Point</td>\n",
       "      <td>Harper</td>\n",
       "      <td>...</td>\n",
       "      <td>30.2816</td>\n",
       "      <td>-99.2410</td>\n",
       "      <td>2395</td>\n",
       "      <td>Pharmacist, community</td>\n",
       "      <td>1993-11-17</td>\n",
       "      <td>2ecaf4f9f576869f25389a393089217e</td>\n",
       "      <td>1336905873</td>\n",
       "      <td>30.301885</td>\n",
       "      <td>-100.135697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date_time               cc_num               merchant  \\\n",
       "844251   2019-12-14 14:24:34     3577578023716568  fraud_Connelly-Carter   \n",
       "1073400  2020-03-22 06:33:04     4822367783500458    fraud_Smitham-Boehm   \n",
       "1035705  2020-03-05 07:38:39  4512828414983801773    fraud_Kutch-Hegmann   \n",
       "1142571  2020-04-20 23:57:09     2222157926772399        fraud_Rau-Grant   \n",
       "269503   2019-05-13 10:44:33       30030380240193       fraud_Terry-Huel   \n",
       "\n",
       "             category     amt        first     last gender  \\\n",
       "844251           home   61.30       Debbie   Hughes      F   \n",
       "1073400   grocery_net   49.51  Christopher  Farrell      M   \n",
       "1035705   grocery_net   50.88       Monica    Cohen      F   \n",
       "1142571     kids_pets  130.63          Amy  Garrett      F   \n",
       "269503   shopping_net   95.43      William  Jenkins      M   \n",
       "\n",
       "                             street         city  ...      lat     long  \\\n",
       "844251   0182 Owens Burgs Suite 480      Diamond  ...  41.0935 -81.0425   \n",
       "1073400         97070 Anderson Land  Haines City  ...  28.0758 -81.5929   \n",
       "1035705         864 Reynolds Plains        Uledi  ...  39.8936 -79.7856   \n",
       "1142571      6014 Thomas Throughway      Trenton  ...  33.4235 -96.3398   \n",
       "269503            50614 Kevin Point       Harper  ...  30.2816 -99.2410   \n",
       "\n",
       "         city_pop                             job         dob  \\\n",
       "844251       2644            Engineer, biomedical  1983-08-25   \n",
       "1073400     33804           Exercise physiologist  1991-01-01   \n",
       "1035705       328                    Tree surgeon  1983-07-25   \n",
       "1142571      2211  Investment banker, operational  1987-02-26   \n",
       "269503       2395           Pharmacist, community  1993-11-17   \n",
       "\n",
       "                                trans_num   unix_time  merch_lat  merch_long  \\\n",
       "844251   26adc9780adf68d32f2806e7e24d9607  1355495074  41.182834  -80.598998   \n",
       "1073400  02e371db409e3999b37e297a3e7b1f49  1363933984  27.454865  -81.846996   \n",
       "1035705  a2db8ea2d74b5970267465073343cc1f  1362469119  39.880428  -80.729349   \n",
       "1142571  d3a3fbb5187f2650287c335489edfb5e  1366502229  34.250078  -95.344471   \n",
       "269503   2ecaf4f9f576869f25389a393089217e  1336905873  30.301885 -100.135697   \n",
       "\n",
       "         is_fraud  \n",
       "844251          0  \n",
       "1073400         0  \n",
       "1035705         0  \n",
       "1142571         0  \n",
       "269503          0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "809f93aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last',\n",
       "       'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop',\n",
       "       'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long',\n",
       "       'is_fraud'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff5e10a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time     0\n",
       "cc_num        0\n",
       "merchant      0\n",
       "category      0\n",
       "amt           0\n",
       "first         0\n",
       "last          0\n",
       "gender        0\n",
       "street        0\n",
       "city          0\n",
       "state         0\n",
       "zip           0\n",
       "lat           0\n",
       "long          0\n",
       "city_pop      0\n",
       "job           0\n",
       "dob           0\n",
       "trans_num     0\n",
       "unix_time     0\n",
       "merch_lat     0\n",
       "merch_long    0\n",
       "is_fraud      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No null data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80deaa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4976.59\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(df['amt'].max())\n",
    "print(df['amt'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfce334",
   "metadata": {},
   "source": [
    "Since there is a huge difference in the max and min values for the transaction amount, I will then scale this column to make the data more practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86b354fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844251    -0.063860\n",
       "1073400   -0.149753\n",
       "1035705   -0.139772\n",
       "1142571    0.441229\n",
       "269503     0.184787\n",
       "             ...   \n",
       "682304    -0.286498\n",
       "898375     0.066328\n",
       "338451     0.038499\n",
       "967983    -0.494202\n",
       "935753    -0.407798\n",
       "Name: amt, Length: 12967, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to standardize the 'amt' column\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "amount = df['amt'].values\n",
    "df['amt'] = sc.fit_transform(amount.reshape(-1, 1))\n",
    "df['amt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75095a74",
   "metadata": {},
   "source": [
    "Everything in the 'amt' or Amount column looks like it has been scaled and so we will move onto the train and test split. While doing EDA, we found out that most of the columns are not correlated with wether or not the transaction is fraudulent. Therefore, we will create a new dataframe that focuses on the features we need. Additionally, it will save running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b113b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = df[['amt', 'is_fraud']]\n",
    "dft = df[['date_time', 'is_fraud']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c09577",
   "metadata": {},
   "source": [
    "## Train Test Split - Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a6987",
   "metadata": {},
   "source": [
    "The first step in creating an ARIMA model is checking if the series is stationary using the Dickey Fuller Test (ADF). The null hypothesis of the ADF test is that the time series is nonstationary. SO if the p-value of the test is less than the significance level (0.05), then we reject the null hypthesis and infer that the time series is stationary. If the p-value > 0.05, then we find the order of differencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992d8d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -114.506069\n",
      "p-value: 0.000000\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from numpy import log\n",
    "\n",
    "result = adfuller(dft.is_fraud)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4b1625",
   "metadata": {},
   "source": [
    "Since P-value is greater than the significance level, let’s move on to see which is the best ARIMA order to use by using the auto_arima tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99fac8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,0,0)(0,0,0)[0]             : AIC=-30364.463, Time=0.82 sec\n",
      " ARIMA(0,0,1)(0,0,0)[0]             : AIC=-30362.463, Time=3.13 sec\n",
      " ARIMA(0,0,2)(0,0,0)[0]             : AIC=-30360.463, Time=1.80 sec\n",
      " ARIMA(0,0,3)(0,0,0)[0]             : AIC=-30360.831, Time=3.51 sec\n",
      " ARIMA(1,0,0)(0,0,0)[0]             : AIC=-30362.463, Time=0.49 sec\n",
      " ARIMA(1,0,1)(0,0,0)[0]             : AIC=-30360.463, Time=3.65 sec\n",
      " ARIMA(1,0,2)(0,0,0)[0]             : AIC=-30358.463, Time=6.20 sec\n",
      " ARIMA(1,0,3)(0,0,0)[0]             : AIC=-30358.831, Time=4.61 sec\n",
      " ARIMA(2,0,0)(0,0,0)[0]             : AIC=-30360.463, Time=2.73 sec\n",
      " ARIMA(2,0,1)(0,0,0)[0]             : AIC=-30358.463, Time=2.92 sec\n",
      " ARIMA(2,0,2)(0,0,0)[0]             : AIC=-30356.463, Time=7.15 sec\n",
      " ARIMA(2,0,3)(0,0,0)[0]             : AIC=-30356.831, Time=3.63 sec\n",
      " ARIMA(3,0,0)(0,0,0)[0]             : AIC=-30360.896, Time=3.08 sec\n",
      " ARIMA(3,0,1)(0,0,0)[0]             : AIC=-30358.896, Time=3.55 sec\n",
      " ARIMA(3,0,2)(0,0,0)[0]             : AIC=-30356.896, Time=4.57 sec\n",
      "\n",
      "Best model:  ARIMA(0,0,0)(0,0,0)[0]          \n",
      "Total fit time: 51.857 seconds\n"
     ]
    }
   ],
   "source": [
    "from pmdarima import auto_arima\n",
    "\n",
    "\n",
    "model_arima= auto_arima(dft.is_fraud,trace=True, error_action='ignore', start_p=1,start_q=1,max_p=3,max_q=3,\n",
    "              suppress_warnings=True,stepwise=False,seasonal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4144eeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 9725\n",
      "Model:                          ARIMA   Log Likelihood               11571.539\n",
      "Date:                Sat, 22 Oct 2022   AIC                         -23139.078\n",
      "Time:                        10:35:42   BIC                         -23124.713\n",
      "Sample:                             0   HQIC                        -23134.209\n",
      "                               - 9725                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0054      9.566      0.001      1.000     -18.743      18.754\n",
      "sigma2         0.0054      0.105      0.052      0.959      -0.200       0.211\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.29   Jarque-Bera (JB):          13202831.22\n",
      "Prob(Q):                              0.59   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.65   Skew:                            13.43\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                       181.50\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "series = dft.is_fraud\n",
    "X = series\n",
    "size = int(len(X) * 0.75)  \n",
    "train, test = X[0:size], X[size:]\n",
    "history = [x for x in train]\n",
    "model = ARIMA(history, order=(0,0,0))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e1384",
   "metadata": {},
   "source": [
    "### Plot Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91d96234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3242,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_test = model_fit.forecast(len(test))\n",
    "forecast_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af62e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00544487 0.00544487 0.00544487 ... 0.00544487 0.00544487 0.00544487]\n"
     ]
    }
   ],
   "source": [
    "print(forecast_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99b1d15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3242,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82da9e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795393     2019-12-02 21:25:04\n",
      "473118     2019-07-27 14:30:28\n",
      "626797     2019-09-23 10:55:48\n",
      "78197      2019-02-16 02:46:15\n",
      "1139708    2020-04-20 03:17:08\n",
      "                  ...         \n",
      "682304     2019-10-18 12:43:19\n",
      "898375     2019-12-26 13:07:12\n",
      "338451     2019-06-09 11:31:21\n",
      "967983     2020-01-26 10:41:26\n",
      "935753     2020-01-06 23:43:35\n",
      "Name: date_time, Length: 3242, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dft['date_time'][size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4d9e14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(dft['date_time'][size:], test, label=\"Test\")\n",
    "plt.scatter(dft['date_time'][size:], forecast_test, label=\"Predicted\")\n",
    "plt.xlabel('Date and Time')\n",
    "plt.ylabel('Is_Fraud')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(np.arange(0, 3242, 1000), rotation = 90)\n",
    "plt.title('Arima Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d9da2",
   "metadata": {},
   "source": [
    "### Plot Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9aa126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = test - forecast_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45f05f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dft['date_time'][size:], diff)\n",
    "plt.xticks(np.arange(0, 3242, 1000), rotation = 90)\n",
    "plt.xlabel('Date and Time')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Residual of Arima')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bc8dc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the residual is 0.0007241622430782345\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "avg = mean(diff)\n",
    "print('The average of the residual is', avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0fd91",
   "metadata": {},
   "source": [
    "Although the average of the residual is low, however, we have to consider that the majority of the data is nonfraudulent data. If we look at the Arima model, it did not predict a single fraudulent behavior when there was some. Let's feed the residual with  the random forest model (with other characteristics)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e8afa",
   "metadata": {},
   "source": [
    "### Random Forest on Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cd81583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>844251</th>\n",
       "      <td>2019-12-14 14:24:34</td>\n",
       "      <td>3577578023716568</td>\n",
       "      <td>fraud_Connelly-Carter</td>\n",
       "      <td>home</td>\n",
       "      <td>-0.063860</td>\n",
       "      <td>Debbie</td>\n",
       "      <td>Hughes</td>\n",
       "      <td>F</td>\n",
       "      <td>0182 Owens Burgs Suite 480</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0935</td>\n",
       "      <td>-81.0425</td>\n",
       "      <td>2644</td>\n",
       "      <td>Engineer, biomedical</td>\n",
       "      <td>1983-08-25</td>\n",
       "      <td>26adc9780adf68d32f2806e7e24d9607</td>\n",
       "      <td>1355495074</td>\n",
       "      <td>41.182834</td>\n",
       "      <td>-80.598998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073400</th>\n",
       "      <td>2020-03-22 06:33:04</td>\n",
       "      <td>4822367783500458</td>\n",
       "      <td>fraud_Smitham-Boehm</td>\n",
       "      <td>grocery_net</td>\n",
       "      <td>-0.149753</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Farrell</td>\n",
       "      <td>M</td>\n",
       "      <td>97070 Anderson Land</td>\n",
       "      <td>Haines City</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0758</td>\n",
       "      <td>-81.5929</td>\n",
       "      <td>33804</td>\n",
       "      <td>Exercise physiologist</td>\n",
       "      <td>1991-01-01</td>\n",
       "      <td>02e371db409e3999b37e297a3e7b1f49</td>\n",
       "      <td>1363933984</td>\n",
       "      <td>27.454865</td>\n",
       "      <td>-81.846996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035705</th>\n",
       "      <td>2020-03-05 07:38:39</td>\n",
       "      <td>4512828414983801773</td>\n",
       "      <td>fraud_Kutch-Hegmann</td>\n",
       "      <td>grocery_net</td>\n",
       "      <td>-0.139772</td>\n",
       "      <td>Monica</td>\n",
       "      <td>Cohen</td>\n",
       "      <td>F</td>\n",
       "      <td>864 Reynolds Plains</td>\n",
       "      <td>Uledi</td>\n",
       "      <td>...</td>\n",
       "      <td>39.8936</td>\n",
       "      <td>-79.7856</td>\n",
       "      <td>328</td>\n",
       "      <td>Tree surgeon</td>\n",
       "      <td>1983-07-25</td>\n",
       "      <td>a2db8ea2d74b5970267465073343cc1f</td>\n",
       "      <td>1362469119</td>\n",
       "      <td>39.880428</td>\n",
       "      <td>-80.729349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142571</th>\n",
       "      <td>2020-04-20 23:57:09</td>\n",
       "      <td>2222157926772399</td>\n",
       "      <td>fraud_Rau-Grant</td>\n",
       "      <td>kids_pets</td>\n",
       "      <td>0.441229</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Garrett</td>\n",
       "      <td>F</td>\n",
       "      <td>6014 Thomas Throughway</td>\n",
       "      <td>Trenton</td>\n",
       "      <td>...</td>\n",
       "      <td>33.4235</td>\n",
       "      <td>-96.3398</td>\n",
       "      <td>2211</td>\n",
       "      <td>Investment banker, operational</td>\n",
       "      <td>1987-02-26</td>\n",
       "      <td>d3a3fbb5187f2650287c335489edfb5e</td>\n",
       "      <td>1366502229</td>\n",
       "      <td>34.250078</td>\n",
       "      <td>-95.344471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269503</th>\n",
       "      <td>2019-05-13 10:44:33</td>\n",
       "      <td>30030380240193</td>\n",
       "      <td>fraud_Terry-Huel</td>\n",
       "      <td>shopping_net</td>\n",
       "      <td>0.184787</td>\n",
       "      <td>William</td>\n",
       "      <td>Jenkins</td>\n",
       "      <td>M</td>\n",
       "      <td>50614 Kevin Point</td>\n",
       "      <td>Harper</td>\n",
       "      <td>...</td>\n",
       "      <td>30.2816</td>\n",
       "      <td>-99.2410</td>\n",
       "      <td>2395</td>\n",
       "      <td>Pharmacist, community</td>\n",
       "      <td>1993-11-17</td>\n",
       "      <td>2ecaf4f9f576869f25389a393089217e</td>\n",
       "      <td>1336905873</td>\n",
       "      <td>30.301885</td>\n",
       "      <td>-100.135697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date_time               cc_num               merchant  \\\n",
       "844251   2019-12-14 14:24:34     3577578023716568  fraud_Connelly-Carter   \n",
       "1073400  2020-03-22 06:33:04     4822367783500458    fraud_Smitham-Boehm   \n",
       "1035705  2020-03-05 07:38:39  4512828414983801773    fraud_Kutch-Hegmann   \n",
       "1142571  2020-04-20 23:57:09     2222157926772399        fraud_Rau-Grant   \n",
       "269503   2019-05-13 10:44:33       30030380240193       fraud_Terry-Huel   \n",
       "\n",
       "             category       amt        first     last gender  \\\n",
       "844251           home -0.063860       Debbie   Hughes      F   \n",
       "1073400   grocery_net -0.149753  Christopher  Farrell      M   \n",
       "1035705   grocery_net -0.139772       Monica    Cohen      F   \n",
       "1142571     kids_pets  0.441229          Amy  Garrett      F   \n",
       "269503   shopping_net  0.184787      William  Jenkins      M   \n",
       "\n",
       "                             street         city  ...      lat     long  \\\n",
       "844251   0182 Owens Burgs Suite 480      Diamond  ...  41.0935 -81.0425   \n",
       "1073400         97070 Anderson Land  Haines City  ...  28.0758 -81.5929   \n",
       "1035705         864 Reynolds Plains        Uledi  ...  39.8936 -79.7856   \n",
       "1142571      6014 Thomas Throughway      Trenton  ...  33.4235 -96.3398   \n",
       "269503            50614 Kevin Point       Harper  ...  30.2816 -99.2410   \n",
       "\n",
       "         city_pop                             job         dob  \\\n",
       "844251       2644            Engineer, biomedical  1983-08-25   \n",
       "1073400     33804           Exercise physiologist  1991-01-01   \n",
       "1035705       328                    Tree surgeon  1983-07-25   \n",
       "1142571      2211  Investment banker, operational  1987-02-26   \n",
       "269503       2395           Pharmacist, community  1993-11-17   \n",
       "\n",
       "                                trans_num   unix_time  merch_lat  merch_long  \\\n",
       "844251   26adc9780adf68d32f2806e7e24d9607  1355495074  41.182834  -80.598998   \n",
       "1073400  02e371db409e3999b37e297a3e7b1f49  1363933984  27.454865  -81.846996   \n",
       "1035705  a2db8ea2d74b5970267465073343cc1f  1362469119  39.880428  -80.729349   \n",
       "1142571  d3a3fbb5187f2650287c335489edfb5e  1366502229  34.250078  -95.344471   \n",
       "269503   2ecaf4f9f576869f25389a393089217e  1336905873  30.301885 -100.135697   \n",
       "\n",
       "         is_fraud  \n",
       "844251          0  \n",
       "1073400         0  \n",
       "1035705         0  \n",
       "1142571         0  \n",
       "269503          0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8354cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe from the residuals\n",
    "df_rf = pd.DataFrame(diff)\n",
    "df_rf = df_rf.rename(columns = {'is_fraud':'residual'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d02690e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>residual</th>\n",
       "      <th>date_time</th>\n",
       "      <th>amt</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005445</td>\n",
       "      <td>2019-12-02 21:25:04</td>\n",
       "      <td>-0.501123</td>\n",
       "      <td>276002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005445</td>\n",
       "      <td>2019-07-27 14:30:28</td>\n",
       "      <td>-0.014611</td>\n",
       "      <td>741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005445</td>\n",
       "      <td>2019-09-23 10:55:48</td>\n",
       "      <td>-0.108883</td>\n",
       "      <td>3684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005445</td>\n",
       "      <td>2019-02-16 02:46:15</td>\n",
       "      <td>-0.480869</td>\n",
       "      <td>11751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005445</td>\n",
       "      <td>2020-04-20 03:17:08</td>\n",
       "      <td>-0.456391</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>-0.005445</td>\n",
       "      <td>2019-10-18 12:43:19</td>\n",
       "      <td>-0.286498</td>\n",
       "      <td>21902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>-0.005445</td>\n",
       "      <td>2019-12-26 13:07:12</td>\n",
       "      <td>0.066328</td>\n",
       "      <td>84106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>-0.005445</td>\n",
       "      <td>2019-06-09 11:31:21</td>\n",
       "      <td>0.038499</td>\n",
       "      <td>4508</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>-0.005445</td>\n",
       "      <td>2020-01-26 10:41:26</td>\n",
       "      <td>-0.494202</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>-0.005445</td>\n",
       "      <td>2020-01-06 23:43:35</td>\n",
       "      <td>-0.407798</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3242 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      residual            date_time       amt  city_pop  is_fraud\n",
       "0    -0.005445  2019-12-02 21:25:04 -0.501123    276002         0\n",
       "1    -0.005445  2019-07-27 14:30:28 -0.014611       741         0\n",
       "2    -0.005445  2019-09-23 10:55:48 -0.108883      3684         0\n",
       "3    -0.005445  2019-02-16 02:46:15 -0.480869     11751         0\n",
       "4    -0.005445  2020-04-20 03:17:08 -0.456391       207         0\n",
       "...        ...                  ...       ...       ...       ...\n",
       "3237 -0.005445  2019-10-18 12:43:19 -0.286498     21902         0\n",
       "3238 -0.005445  2019-12-26 13:07:12  0.066328     84106         0\n",
       "3239 -0.005445  2019-06-09 11:31:21  0.038499      4508         0\n",
       "3240 -0.005445  2020-01-26 10:41:26 -0.494202       350         0\n",
       "3241 -0.005445  2020-01-06 23:43:35 -0.407798      1186         0\n",
       "\n",
       "[3242 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf['date_time'] = df['date_time'][size:]\n",
    "df_rf['amt'] = df['amt'][size:]\n",
    "df_rf['city_pop'] = df['city_pop'][size:]\n",
    "df_rf['is_fraud'] = df['is_fraud'][size:]\n",
    "df_rf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ccf82ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_rf[['amt', 'city_pop']]\n",
    "y = df_rf['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6e3b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34edbe57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier())"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb9a0802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f58be",
   "metadata": {},
   "source": [
    "This means that between transaction amount and city population, transaction amount is the best feature we should look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcf03570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It will return an Integer representing the number of features selected by the random forest\n",
    "\n",
    "selected_feat= X_train.columns[(sel.get_support())]\n",
    "len(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22519d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['amt'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5698d1",
   "metadata": {},
   "source": [
    "Seeing as transaction amount is the best feature to look at, we will do further analysis on transaction amount and the residuals from our arima model in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209eae66",
   "metadata": {},
   "source": [
    "## Train Test Split - Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4e796f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfa.drop('is_fraud', axis = 1).values\n",
    "y = dfa['is_fraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8bfeb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e0499",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c9cb9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "DT.fit(X_train, y_train)\n",
    "dt_yhat = DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2ce1be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Decision Tree model is 0.9950647748303516\n",
      "F1 score of the Decision Tree model is 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3224,    1],\n",
       "       [  15,    2]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, dt_yhat)))\n",
    "print('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, dt_yhat)))\n",
    "confusion_matrix(y_test, dt_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de01b46",
   "metadata": {},
   "source": [
    "Here, the first row represents positive and the second row represents negative. So, we have 3219 as true positive and 0 are false positive. We have 3219 that are successfully classified as a nonfraudulent transaction and 0 were falsely classified as nonfraudulent, but they were fraudulent. For the accuracy and F1 score, generally we want the score closer to 1. The accuracy score of the Decision Tree model is pretty good but the F1 score is alright."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8c1c7",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6b68ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n = 7\n",
    "KNN = KNeighborsClassifier(n_neighbors = n)\n",
    "KNN.fit(X_train, y_train)\n",
    "knn_yhat = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "259d5b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the K-Nearest Neighbors model is 0.9947563232572486\n",
      "F1 score of the K-Nearest Neighbors model is 0.2608695652173913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3222,    3],\n",
       "       [  14,    3]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy score of the K-Nearest Neighbors model is {}'.format(accuracy_score(y_test, knn_yhat)))\n",
    "print('F1 score of the K-Nearest Neighbors model is {}'.format(f1_score(y_test, knn_yhat)))\n",
    "confusion_matrix(y_test, knn_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc8c11",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ff421fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_yhat = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d030c609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Logistic Regression model is 0.9938309685379395\n",
      "F1 score of the Logistic Regression model is 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3222,    3],\n",
       "       [  17,    0]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)))\n",
    "print('F1 score of the Logistic Regression model is {}'.format(f1_score(y_test, lr_yhat)))\n",
    "confusion_matrix(y_test, lr_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a1cc2",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5acebb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth = 4)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_yhat = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dafb5dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Random Forest model is 0.9950647748303516\n",
      "F1 score of the Random Forest model is 0.2727272727272727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3223,    2],\n",
       "       [  14,    3]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy score of the Random Forest model is {}'.format(accuracy_score(y_test, rf_yhat)))\n",
    "print('F1 score of the Random Forest model is {}'.format(f1_score(y_test, rf_yhat)))\n",
    "confusion_matrix(y_test, rf_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4b8ba1",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9250be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(max_depth = 4)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_yhat = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56e31568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the XGBoost model is 0.9947563232572486\n",
      "F1 score of the XGBoost model is 0.31999999999999995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3221,    4],\n",
       "       [  13,    4]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat)))\n",
    "print('F1 score of the XGBoost model is {}'.format(f1_score(y_test, xgb_yhat)))\n",
    "confusion_matrix(y_test, xgb_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd2f2c",
   "metadata": {},
   "source": [
    "### Hybrid XGBoost Model - XGBoost and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e062e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "xgbrf = XGBRFClassifier()\n",
    "xgbrf.fit(X_train, y_train)\n",
    "xgbrf_yhat = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac98e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the XGBRF model is 0.9947563232572486\n",
      "F1 score of the XGBRF model is 0.31999999999999995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3221,    4],\n",
       "       [  13,    4]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy score of the XGBRF model is {}'.format(accuracy_score(y_test, xgbrf_yhat)))\n",
    "print('F1 score of the XGBRF model is {}'.format(f1_score(y_test, xgbrf_yhat)))\n",
    "confusion_matrix(y_test, xgbrf_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43601a17",
   "metadata": {},
   "source": [
    "## Overall Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "527b789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [accuracy_score(y_test, dt_yhat), accuracy_score(y_test, knn_yhat), accuracy_score(y_test, lr_yhat), \n",
    "            accuracy_score(y_test, xgb_yhat), accuracy_score(y_test, xgbrf_yhat)]\n",
    "f1 = [f1_score(y_test, dt_yhat), f1_score(y_test, knn_yhat), f1_score(y_test, lr_yhat), \n",
    "            f1_score(y_test, xgb_yhat), f1_score(y_test, xgbrf_yhat)]\n",
    "names = ['DT', 'KNN', 'LR', 'XGB', 'XBGRF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94257882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(accuracy, f1, names):\n",
    "    for i in range(0, 5):\n",
    "        print('For', names[i])\n",
    "        print('It has an accuracy score of', accuracy[i])\n",
    "        print('And an F1 score of', f1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6fe8630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For DT\n",
      "It has an accuracy score of 0.9950647748303516\n",
      "And an F1 score of 0.2\n",
      "For KNN\n",
      "It has an accuracy score of 0.9947563232572486\n",
      "And an F1 score of 0.2608695652173913\n",
      "For LR\n",
      "It has an accuracy score of 0.9938309685379395\n",
      "And an F1 score of 0.0\n",
      "For XGB\n",
      "It has an accuracy score of 0.9947563232572486\n",
      "And an F1 score of 0.31999999999999995\n",
      "For XBGRF\n",
      "It has an accuracy score of 0.9947563232572486\n",
      "And an F1 score of 0.31999999999999995\n"
     ]
    }
   ],
   "source": [
    "scores(accuracy, f1, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88633bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950647748303516"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "558f5d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31999999999999995"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f7a8c0",
   "metadata": {},
   "source": [
    "Decision Tree Classifier has the highest accuracy score but XGBoost and XGBoost/Random Forest has the highest F1 score. So how do we choose between the two?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46150a0e",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee83578e",
   "metadata": {},
   "source": [
    "Remember that the F1 score is balancing precision and recall on the positive class while accuracy looks at correctly classified observations both positive and negative. That makes a big difference especially for the imbalanced problems where by default our model will be good at predicting true negatives and hence accuracy will be high. However, if you care equally about true negatives and true positives then accuracy is the metric you should choose. \n",
    "\n",
    "Since our dataset is naturally imbalanced, it will make our accuracy score really high by default. That is why we will care more about the F1 score in this case.\n",
    "\n",
    "Therefore, the best model is the XGBoost and XGBRF which has the same accuracy and F1 score. We have an accuracy of 99.35% and a F1 score of 32.26%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec5fc6",
   "metadata": {},
   "source": [
    "### Using Random Forest on Residuals (In the Works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "784489a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2431,)\n",
      "(811,)\n"
     ]
    }
   ],
   "source": [
    "X_test = df_rf['residual'][int(len(df_rf)*0.75):].values\n",
    "X_train = df_rf['residual'][:int(len(df_rf)*0.75)].values\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f99626d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_rf['is_fraud'][int(len(df_rf)*0.75):].values\n",
    "y_train = df_rf['is_fraud'][:int(len(df_rf)*0.75)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5760ad87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487  0.9945551\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487  0.9945551  -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487  0.9945551  -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n  0.9945551  -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n  0.9945551  -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n  0.9945551  -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      2\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), y_train)\n\u001b[1;32m----> 3\u001b[0m rf_yhat \u001b[38;5;241m=\u001b[39m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:808\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 808\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:850\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    848\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    853\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 579\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:769\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    770\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    771\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    772\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    773\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    774\u001b[0m         )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# make sure we actually converted to numeric:\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487  0.9945551\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487  0.9945551  -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487  0.9945551  -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n  0.9945551  -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n  0.9945551  -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n  0.9945551  -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487 -0.00544487\n -0.00544487].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth = 4)\n",
    "rf.fit(X_train.reshape(-1,1), y_train)\n",
    "rf_yhat = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a9fba",
   "metadata": {},
   "source": [
    "I tried to use a random forest on the residual but it did not work. I wonder if it had something to do with the Arima model since it did poorly in predicting if the work is fraudlent or not. So when I tried to do a random forest with other features, it did not go as planned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7bbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
