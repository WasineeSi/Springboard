{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07086a5f",
   "metadata": {},
   "source": [
    "# Preprocessing Training and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e8acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800e98c",
   "metadata": {},
   "source": [
    "## Preprocessing and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbbf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fraudTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b14a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleted first column since it was the same as the index\n",
    "df = df.iloc[: , 1:]\n",
    "# We are going to rename some columns for ease\n",
    "df = df.rename(columns={'trans_date_trans_time':'date_time'})\n",
    "# We want to change the data type of the 'date_time' column to datetime data type for easier manipulation of data\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "df['date_time'].dtypes\n",
    "# Drop any duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9bd3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1296675, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb36daf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12967, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's downsize the data for ease of speed\n",
    "df = df.sample(frac=0.01)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dbf6dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500767</th>\n",
       "      <td>2019-08-05 14:34:59</td>\n",
       "      <td>6506982560413523</td>\n",
       "      <td>fraud_Beier-Hyatt</td>\n",
       "      <td>shopping_pos</td>\n",
       "      <td>2.18</td>\n",
       "      <td>Alice</td>\n",
       "      <td>Kemp</td>\n",
       "      <td>F</td>\n",
       "      <td>057 Martinez Radial</td>\n",
       "      <td>Texarkana</td>\n",
       "      <td>...</td>\n",
       "      <td>33.4310</td>\n",
       "      <td>-93.8765</td>\n",
       "      <td>36438</td>\n",
       "      <td>Surgeon</td>\n",
       "      <td>1985-04-15</td>\n",
       "      <td>fe78243a04b93f77f72271f49e178460</td>\n",
       "      <td>1344177299</td>\n",
       "      <td>34.179876</td>\n",
       "      <td>-93.768268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784441</th>\n",
       "      <td>2019-12-01 03:09:14</td>\n",
       "      <td>502038091380</td>\n",
       "      <td>fraud_Barton Inc</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>93.66</td>\n",
       "      <td>Kurt</td>\n",
       "      <td>Peters</td>\n",
       "      <td>M</td>\n",
       "      <td>7290 Ashlee Keys</td>\n",
       "      <td>Kissee Mills</td>\n",
       "      <td>...</td>\n",
       "      <td>36.6704</td>\n",
       "      <td>-93.0377</td>\n",
       "      <td>1201</td>\n",
       "      <td>Engineer, agricultural</td>\n",
       "      <td>1980-03-18</td>\n",
       "      <td>a0063670117d27d3de3ac3a7ba279e9d</td>\n",
       "      <td>1354331354</td>\n",
       "      <td>36.774243</td>\n",
       "      <td>-93.523791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519637</th>\n",
       "      <td>2019-08-12 08:38:40</td>\n",
       "      <td>180049032966888</td>\n",
       "      <td>fraud_Little, Gutmann and Lynch</td>\n",
       "      <td>shopping_net</td>\n",
       "      <td>99.82</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Flores</td>\n",
       "      <td>M</td>\n",
       "      <td>70761 Fitzpatrick Brooks Suite 631</td>\n",
       "      <td>Saxon</td>\n",
       "      <td>...</td>\n",
       "      <td>46.4959</td>\n",
       "      <td>-90.4383</td>\n",
       "      <td>795</td>\n",
       "      <td>Television/film/video producer</td>\n",
       "      <td>1986-04-15</td>\n",
       "      <td>5dfbfb5b5b3a357a5fef0d599a2647d0</td>\n",
       "      <td>1344760720</td>\n",
       "      <td>46.296291</td>\n",
       "      <td>-89.489390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150334</th>\n",
       "      <td>2020-04-24 21:18:06</td>\n",
       "      <td>4452366298769043</td>\n",
       "      <td>fraud_Turner, Ruecker and Parisian</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>317.19</td>\n",
       "      <td>Linda</td>\n",
       "      <td>Davis</td>\n",
       "      <td>F</td>\n",
       "      <td>6602 Ortiz Pine Apt. 179</td>\n",
       "      <td>Blooming Grove</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0758</td>\n",
       "      <td>-96.7010</td>\n",
       "      <td>1563</td>\n",
       "      <td>Financial adviser</td>\n",
       "      <td>1978-03-04</td>\n",
       "      <td>8122ee0845b03f9aa5fc162530320432</td>\n",
       "      <td>1366838286</td>\n",
       "      <td>31.369695</td>\n",
       "      <td>-96.949437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348021</th>\n",
       "      <td>2019-06-12 17:41:31</td>\n",
       "      <td>2288813824604479</td>\n",
       "      <td>fraud_Gottlieb-Hansen</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>20.66</td>\n",
       "      <td>Barbara</td>\n",
       "      <td>Norman</td>\n",
       "      <td>F</td>\n",
       "      <td>6278 Stephanie Unions</td>\n",
       "      <td>New York City</td>\n",
       "      <td>...</td>\n",
       "      <td>40.8265</td>\n",
       "      <td>-73.9383</td>\n",
       "      <td>1577385</td>\n",
       "      <td>Herbalist</td>\n",
       "      <td>1981-08-29</td>\n",
       "      <td>1edbd647c515874abbcf8bdf051cab61</td>\n",
       "      <td>1339522891</td>\n",
       "      <td>40.795240</td>\n",
       "      <td>-74.840796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date_time            cc_num  \\\n",
       "500767  2019-08-05 14:34:59  6506982560413523   \n",
       "784441  2019-12-01 03:09:14      502038091380   \n",
       "519637  2019-08-12 08:38:40   180049032966888   \n",
       "1150334 2020-04-24 21:18:06  4452366298769043   \n",
       "348021  2019-06-12 17:41:31  2288813824604479   \n",
       "\n",
       "                                   merchant       category     amt    first  \\\n",
       "500767                    fraud_Beier-Hyatt   shopping_pos    2.18    Alice   \n",
       "784441                     fraud_Barton Inc    grocery_pos   93.66     Kurt   \n",
       "519637      fraud_Little, Gutmann and Lynch   shopping_net   99.82  Michael   \n",
       "1150334  fraud_Turner, Ruecker and Parisian       misc_pos  317.19    Linda   \n",
       "348021                fraud_Gottlieb-Hansen  personal_care   20.66  Barbara   \n",
       "\n",
       "           last gender                              street            city  \\\n",
       "500767     Kemp      F                 057 Martinez Radial       Texarkana   \n",
       "784441   Peters      M                    7290 Ashlee Keys    Kissee Mills   \n",
       "519637   Flores      M  70761 Fitzpatrick Brooks Suite 631           Saxon   \n",
       "1150334   Davis      F            6602 Ortiz Pine Apt. 179  Blooming Grove   \n",
       "348021   Norman      F               6278 Stephanie Unions   New York City   \n",
       "\n",
       "         ...      lat     long  city_pop                             job  \\\n",
       "500767   ...  33.4310 -93.8765     36438                         Surgeon   \n",
       "784441   ...  36.6704 -93.0377      1201          Engineer, agricultural   \n",
       "519637   ...  46.4959 -90.4383       795  Television/film/video producer   \n",
       "1150334  ...  32.0758 -96.7010      1563               Financial adviser   \n",
       "348021   ...  40.8265 -73.9383   1577385                       Herbalist   \n",
       "\n",
       "                dob                         trans_num   unix_time  merch_lat  \\\n",
       "500767   1985-04-15  fe78243a04b93f77f72271f49e178460  1344177299  34.179876   \n",
       "784441   1980-03-18  a0063670117d27d3de3ac3a7ba279e9d  1354331354  36.774243   \n",
       "519637   1986-04-15  5dfbfb5b5b3a357a5fef0d599a2647d0  1344760720  46.296291   \n",
       "1150334  1978-03-04  8122ee0845b03f9aa5fc162530320432  1366838286  31.369695   \n",
       "348021   1981-08-29  1edbd647c515874abbcf8bdf051cab61  1339522891  40.795240   \n",
       "\n",
       "         merch_long  is_fraud  \n",
       "500767   -93.768268         0  \n",
       "784441   -93.523791         0  \n",
       "519637   -89.489390         0  \n",
       "1150334  -96.949437         0  \n",
       "348021   -74.840796         0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "809f93aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last',\n",
       "       'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop',\n",
       "       'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long',\n",
       "       'is_fraud'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff5e10a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time     0\n",
       "cc_num        0\n",
       "merchant      0\n",
       "category      0\n",
       "amt           0\n",
       "first         0\n",
       "last          0\n",
       "gender        0\n",
       "street        0\n",
       "city          0\n",
       "state         0\n",
       "zip           0\n",
       "lat           0\n",
       "long          0\n",
       "city_pop      0\n",
       "job           0\n",
       "dob           0\n",
       "trans_num     0\n",
       "unix_time     0\n",
       "merch_lat     0\n",
       "merch_long    0\n",
       "is_fraud      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No null data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80deaa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15305.95\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(df['amt'].max())\n",
    "print(df['amt'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfce334",
   "metadata": {},
   "source": [
    "Since there is a huge difference in the max and min values for the transaction amount, I will then scale this column to make the data more practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86b354fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500767    -0.376352\n",
       "784441     0.133939\n",
       "519637     0.168301\n",
       "1150334    1.380829\n",
       "348021    -0.273268\n",
       "             ...   \n",
       "8395      -0.093539\n",
       "1249845   -0.181562\n",
       "848046    -0.055775\n",
       "260209     0.451003\n",
       "1200601   -0.128068\n",
       "Name: amt, Length: 12967, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to standardize the 'amt' column\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "amount = df['amt'].values\n",
    "df['amt'] = sc.fit_transform(amount.reshape(-1, 1))\n",
    "df['amt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75095a74",
   "metadata": {},
   "source": [
    "Everything in the 'amt' or Amount column looks like it has been scaled and so we will move onto the train and test split. While doing EDA, we found out that most of the columns are not correlated with wether or not the transaction is fraudulent. Therefore, we will create a new dataframe that focuses on the features we need. Additionally, it will save running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b113b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = df[['amt', 'is_fraud']]\n",
    "dft = df[['date_time', 'is_fraud']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209eae66",
   "metadata": {},
   "source": [
    "## Train Test Split - Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e796f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfa.drop('is_fraud', axis = 1).values\n",
    "y = dfa['is_fraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8bfeb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e0499",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c9cb9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "DT.fit(X_train, y_train)\n",
    "dt_yhat = DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2ce1be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Decision Tree model is 0.9938309685379395\n",
      "F1 score of the Decision Tree model is 0.23076923076923078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3219,    0],\n",
       "       [  20,    3]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, dt_yhat)))\n",
    "print('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, dt_yhat)))\n",
    "confusion_matrix(y_test, dt_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de01b46",
   "metadata": {},
   "source": [
    "Here, the first row represents positive and the second row represents negative. So, we have 3219 as true positive and 0 are false positive. We have 3219 that are successfully classified as a nonfraudulent transaction and 0 were falsely classified as nonfraudulent, but they were fraudulent. For the accuracy and F1 score, generally we want the score closer to 1. The accuracy score of the Decision Tree model is pretty good but the F1 score is alright."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8c1c7",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6b68ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n = 7\n",
    "KNN = KNeighborsClassifier(n_neighbors = n)\n",
    "KNN.fit(X_train, y_train)\n",
    "knn_yhat = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "259d5b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the K-Nearest Neighbors model is 0.9935225169648365\n",
      "F1 score of the K-Nearest Neighbors model is 0.16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3219,    0],\n",
       "       [  21,    2]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy score of the K-Nearest Neighbors model is {}'.format(accuracy_score(y_test, knn_yhat)))\n",
    "print('F1 score of the K-Nearest Neighbors model is {}'.format(f1_score(y_test, knn_yhat)))\n",
    "confusion_matrix(y_test, knn_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cbc241",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b6baf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# List Hyperparameters that we want to tune\n",
    "KNN_2 = KNeighborsClassifier()\n",
    "k_range = list(range(1, 31))\n",
    "print(k_range)\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc8c11",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ff421fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_yhat = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d030c609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Logistic Regression model is 0.9919802590993214\n",
      "F1 score of the Logistic Regression model is 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3216,    3],\n",
       "       [  23,    0]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)))\n",
    "print('F1 score of the Logistic Regression model is {}'.format(f1_score(y_test, lr_yhat)))\n",
    "confusion_matrix(y_test, lr_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a1cc2",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5acebb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth = 4)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_yhat = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dafb5dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Random Forest model is 0.9935225169648365\n",
      "F1 score of the Random Forest model is 0.22222222222222218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3218,    1],\n",
       "       [  20,    3]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy score of the Random Forest model is {}'.format(accuracy_score(y_test, rf_yhat)))\n",
    "print('F1 score of the Random Forest model is {}'.format(f1_score(y_test, rf_yhat)))\n",
    "confusion_matrix(y_test, rf_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4b8ba1",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9250be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(max_depth = 4)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_yhat = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56e31568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the XGBoost model is 0.9935225169648365\n",
      "F1 score of the XGBoost model is 0.3225806451612903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3216,    3],\n",
       "       [  18,    5]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat)))\n",
    "print('F1 score of the XGBoost model is {}'.format(f1_score(y_test, xgb_yhat)))\n",
    "confusion_matrix(y_test, xgb_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd2f2c",
   "metadata": {},
   "source": [
    "### Hybrid XGBoost Model - XGBoost and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e062e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "xgbrf = XGBRFClassifier()\n",
    "xgbrf.fit(X_train, y_train)\n",
    "xgbrf_yhat = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac98e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the XGBRF model is 0.9935225169648365\n",
      "F1 score of the XGBRF model is 0.3225806451612903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3216,    3],\n",
       "       [  18,    5]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy score of the XGBRF model is {}'.format(accuracy_score(y_test, xgbrf_yhat)))\n",
    "print('F1 score of the XGBRF model is {}'.format(f1_score(y_test, xgbrf_yhat)))\n",
    "confusion_matrix(y_test, xgbrf_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43601a17",
   "metadata": {},
   "source": [
    "## Overall Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "527b789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [accuracy_score(y_test, dt_yhat), accuracy_score(y_test, knn_yhat), accuracy_score(y_test, lr_yhat), \n",
    "            accuracy_score(y_test, xgb_yhat), accuracy_score(y_test, xgbrf_yhat)]\n",
    "f1 = [f1_score(y_test, dt_yhat), f1_score(y_test, knn_yhat), f1_score(y_test, lr_yhat), \n",
    "            f1_score(y_test, xgb_yhat), f1_score(y_test, xgbrf_yhat)]\n",
    "names = ['DT', 'KNN', 'LR', 'XGB', 'XBGRF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94257882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(accuracy, f1, names):\n",
    "    for i in range(0, 5):\n",
    "        print('For', names[i])\n",
    "        print('It has an accuracy score of', accuracy[i])\n",
    "        print('And an F1 score of', f1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6fe8630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For DT\n",
      "It has an accuracy score of 0.9938309685379395\n",
      "And an F1 score of 0.23076923076923078\n",
      "For KNN\n",
      "It has an accuracy score of 0.9935225169648365\n",
      "And an F1 score of 0.16\n",
      "For LR\n",
      "It has an accuracy score of 0.9919802590993214\n",
      "And an F1 score of 0.0\n",
      "For XGB\n",
      "It has an accuracy score of 0.9935225169648365\n",
      "And an F1 score of 0.3225806451612903\n",
      "For XBGRF\n",
      "It has an accuracy score of 0.9935225169648365\n",
      "And an F1 score of 0.3225806451612903\n"
     ]
    }
   ],
   "source": [
    "scores(accuracy, f1, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88633bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9938309685379395"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "558f5d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3225806451612903"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f7a8c0",
   "metadata": {},
   "source": [
    "Decision Tree Classifier has the highest accuracy score but XGBoost and XGBoost/Random Forest has the highest F1 score. So how do we choose between the two?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46150a0e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee83578e",
   "metadata": {},
   "source": [
    "Remember that the F1 score is balancing precision and recall on the positive class while accuracy looks at correctly classified observations both positive and negative. That makes a big difference especially for the imbalanced problems where by default our model will be good at predicting true negatives and hence accuracy will be high. However, if you care equally about true negatives and true positives then accuracy is the metric you should choose. \n",
    "\n",
    "Since our dataset is naturally imbalanced, it will make our accuracy score really high by default. That is why we will care more about the F1 score in this case.\n",
    "\n",
    "Therefore, the best model is the XGBoost and XGBRF which has the same accuracy and F1 score. We have an accuracy of 99.35% and a F1 score of 32.26%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc3000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
